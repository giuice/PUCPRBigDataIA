{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = pd.read_csv(\"a.csv\")\n",
    "df_b = pd.read_csv(\"b.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divido a base em treino e teste\n",
    "def train_validation_score(df):\n",
    "    X_, y_ = df.iloc[:,:-1], df.iloc[:, -1]\n",
    "    # Aplico o holdout\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.3, random_state=1)\n",
    "    # Instancio o classificador e imprimo os resultados\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Holdout Acurácia: %0.2f\" % (accuracy_score(y_test, y_pred)))\n",
    "    scores = cross_val_score(clf, X=X_train, y=y_train, cv=5)\n",
    "    print(\"Cross Validation-Acurácia: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout df_a Cross-validation df_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout Acurácia: 0.69\n",
      "Cross Validation-Acurácia: 0.68 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "train_validation_score(df_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout df_b Cross-validation df_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout Acurácia: 0.71\n",
      "Cross Validation-Acurácia: 0.68 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "train_validation_score(df_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parágrafo argumentativo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prós da estratégia de Holdout: dados totalmente independentes; só precisa ser executado uma vez, para ter custos computacionais mais baixos.\n",
    "\n",
    "Contras da estratégia de Holdout: A avaliação de desempenho está sujeita a uma variação maior, devido ao tamanho menor dos dados.\n",
    "\n",
    "Prós da estratégia K-fold: Propenso a menos variação, porque usa todo o conjunto de treinamento.\n",
    "\n",
    "Contras da estratégia K-fold: Custos computacionais mais altos; o modelo precisa ser treinado K vezes na etapa de validação (mais uma na etapa de teste).\n",
    "\n",
    "Diante estas considerações podemos considerar que holdout é geralmente menos eficaz que CV, mas pode ser usado em grandes datasets pela performance e a quantidade de dados permitir uma melhor generalização que poucos dados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
